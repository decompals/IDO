
SPOTLIGHT ILLUMINATION EMPLOYING PROJECTIVE TEXTURE MAPPING

	by Carl Korobkin
           Nov. 1992

  This demonstration code illustrates the basic use of projective
texture mapping to simulate the effect of a spotlight or slide
projector illuminating arbitrary surfaces in an environment.
  Conceptually, the light is a texture map with an associated view
frustum which may be arbitrarily positioned in the scene, independent
of the eye. The plane of projection or "screen" of this frustum
corresponds to the texture map image.  In this "two-viewer" environment,
the light or texture projector is maintained in terms of a 4x4 texture
matrix while the eye-viewer is maintained by the standard 4x4 ModelView
and Projection matrices. For more details, see [1].
  In this example, the host maintains the composite projective
texture matrix (Mtex) as well as the separate texture projection
matrix (MtexProjection).  The separate texture projection is
static since only the orientation of the light (i.e. texture frustum),
and not it's projection paramaters (e.g. field-of-view), is modified.  
The function update_texture_matrix() builds the current composite
texture matrix (Mtex). In this exmaple, the texture projection matrix,
MtexProjection, is specified using the standard gl perspective() call.
By gl definition, this perspective produces "visible" coordinates in
the range of -1 to +1 in each dimension. However, the gl defines
"visible" texture coordinates in the range of 0 to 1 in each dimension.
Therefore, update_texture_matrix() must map texture coordinates in 
the -1 to 1 range (produced by the perspective transformation) to
texture coordinates in the 0 to 1 range. This process, accomplished
by calling a scale(.5,.5,1.) and a translate(1.,1.,0.), amounts to
mapping the visible screen of the texture frustum to the "screen"
of the texture, which is the image of the texture itself. The fate
of pixels outside the 0 to 1 texture coordinate range is determined
by the texture function specified by the user. In this application,
the TX_SELECT property is used to kill pixels outside the 0 to 1
range of the texture projection. This is the desired effect, since
a slide projector would not illuminate beyond the limits of it's
projection frustum.
  Homogeneous texture coordinates are either generated by the user 
and specified using the t4f() texture coordinate command or are 
are automatically generated by the graphics subsystem via the texgen
mechanism. Texture coordinates are produced relative to either
object-space or eye-space geometry coordinates:

    object-space:
    ------------

	[x y z w]  * [Mtex} = [s' t' r' q]
               obj

    eye-space:
    ---------

	[x y z w]  * [Modelview] = [x y z w]
               obj                         eye


	[x y z w]  * [Mtex} = [s' t' r' q]
               eye 


When using texgen, texture coordinates are generated relative to 
object-space or eye-space geometry by specifiying the functions
TG_LINEAR or TG_CONTOUR, respectively.  The texture coordinate to be
generated is specified by TX_S, TX_T, TX_R, and TX_Q, for s, t, r, and
q, respectively.
  In the present example, TG_LINEAR is used to produce texture
coordinates from object-space geometry. To generate s,t,r, and q,
we specify plane equations of [1 0 0 0] with TX_S. [0 1 0 0] with TX_T,
[0 0 1 0] with TX_R, and [0 0 0 1] with TX_Q. This produces the
desired object-relative transformation (as shown above), which is
to take each incoming object vertex [x y z w] and multiply it by
the texture matrix Mtex.
  When the texgen model is TG_CONTOUR, the geometry coordinates are,
by definition, first transformed by the eye's ModelView matrix and then
transformed by the texture matrix Mtex. This would produce the correct
eye-relative transformation (as shown above). 
  Given that the hardware has a single texture mapping resource,
application of projective textures to surfaces which are themselves
textured implies multi-pass rendering. Demonstrated here is
a four-pass rendering technique:

    pass 1:  On the first pass, the frame buffer is cleared to a
             constant value which represents the ambient illumination
             of the scene. The scene geometry is drawn in order to
             resolve z from the eye's point of view.
    pass 2:  The scene is redrawn on the second pass with light
             intensity, in the form of projective texture, added
             to the ambient value if and only if the pixel is the
             most visible to the eye (i.e. on a zfunction of ZF_ZEQUAL).
             The textures being projected are defined with the
             TX_SELECT property. This means that pixels outside the
             0 to 1 range, in either s or t, are killed. Thus,
	     pixels are not "illuminated" if they are not contained
             by the intersection of the projector and a given surface
             element.
    pass 3:  On the third pass, the z-buffer is cleared and the
             scene geometry is drawn in order to resolve z (again
             from eye's point of view). This z is required for
             another "z-equals" drawing of the scene in pass 4.
             This may seem unnecessary, since z was already
             resolved in pass 1. However, the gl does not guarantee
             that identical z values are obtained from one mode of
             drawing path to another. In the current situation, z
             on pass 1 is aquired in a texgen drawing mode and
             tested against on pass 2, while still in a texgen
             mode. On pass 4, drawing is not done in a texgen
             mode, and thus the z values may not match up.
             Pass 3 re-aquires the eye's z-buffer in the
             same draw mode in which it will be tested on pass 4. 
    pass 4:  On the fourth and final pass, the scene is redrawn at full
             brightness with orthogonally applied surface textures and
             is attenuated by the lighting solution (spotlight + ambient)
             in the frame buffer.


  Arbitrary clipping planes are placed at near and far locations
perpendicular to the line-of-sight of the texture. The near plane
is useful for the elimination of texture projection along the
negative line-of-sight of the texture ("back-projection").
The far plane is useful for the elimination of texture projection
on distant surfaces. Again, since the gl does not guarantee that
identical z values are obtained from different rendering paths,
the clipping planes are enabled for both the pass when z is aquired
and the pass when it is used (the first and second passes).
  One effect that this example program does not account for is
the ellimination of texture illumination on surfaces which are
back-facing with respect to the texture's point-of-view. Thus,
one will notice that when the texture projector is moved behind
one of the walls, the projection of the texture shows through
from the surfaces back face.

--------------------------------------------------------------


[1]  Mark Segal, Carl Korobkin, Rolf Van Widenfelt, Paul Haeberli,
     and Jim Foran. Fast Shadows and Lighting Effects Using Texture
     Mapping. In Proceedings of SIGGRAPH '92, pages 249-252, 1992.
